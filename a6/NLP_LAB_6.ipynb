{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "oDFGHUTVsvdW",
        "outputId": "e6d0e3cd-6bf7-4665-eb9a-5c491f72c3da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Greedy: 100%|██████████| 100/100 [04:53<00:00,  2.94s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 100 sentences to /content/generated_sentences/katz_greedy.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Beam:   0%|          | 0/100 [01:39<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3348112009.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    171\u001b[0m generate_and_save(gen_katz, \"Greedy\", 100,\n\u001b[1;32m    172\u001b[0m                   \"/content/generated_sentences/katz_greedy.txt\")\n\u001b[0;32m--> 173\u001b[0;31m generate_and_save(gen_katz, \"Beam\", 100,\n\u001b[0m\u001b[1;32m    174\u001b[0m                   \"/content/generated_sentences/katz_beam.txt\")\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3348112009.py\u001b[0m in \u001b[0;36mgenerate_and_save\u001b[0;34m(generator, method, n, out_file)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgreedy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                 \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeam_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m             \u001b[0msentences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3348112009.py\u001b[0m in \u001b[0;36mbeam_search\u001b[0;34m(self, beam_size, max_len)\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m                     \u001b[0mnew_beams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1e-12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m             \u001b[0mbeams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_beams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbeam_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbeams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# Quadgram LM + Katz Backoff + Kneser–Ney + Sentence Generation\n",
        "# (Greedy + Beam search) with progress bar and file saving\n",
        "# ============================================================\n",
        "\n",
        "import pickle\n",
        "from collections import Counter\n",
        "import math\n",
        "from tqdm import tqdm   # <-- for progress bar\n",
        "\n",
        "# -------------------------------\n",
        "# 1️⃣ Load dataset & build counts\n",
        "# -------------------------------\n",
        "with open(\"/content/tokenized_data_complete.pkl\", \"rb\") as f:   # <-- change to your file\n",
        "    data = pickle.load(f)\n",
        "\n",
        "# Fix: Iterate directly through the list and access the 'tokens' key\n",
        "sentences = [s[\"sentences\"] for s in data]\n",
        "\n",
        "uni_counts  = Counter()\n",
        "bi_counts   = Counter()\n",
        "tri_counts  = Counter()\n",
        "quad_counts = Counter()\n",
        "\n",
        "for sentence_list in sentences:\n",
        "    for token_info in sentence_list:\n",
        "        seq = [\"<s>\", \"<s>\", \"<s>\"] + token_info[\"tokens\"] + [\"</s>\"]\n",
        "        for i in range(len(seq)):\n",
        "            uni_counts[seq[i]] += 1\n",
        "            if i >= 1:\n",
        "                bi_counts[(seq[i-1], seq[i])] += 1\n",
        "            if i >= 2:\n",
        "                tri_counts[(seq[i-2], seq[i-1], seq[i])] += 1\n",
        "            if i >= 3:\n",
        "                quad_counts[(seq[i-3], seq[i-2], seq[i-1], seq[i])] += 1\n",
        "\n",
        "counts_all = [uni_counts, bi_counts, tri_counts, quad_counts]\n",
        "vocab = list(uni_counts.keys())\n",
        "\n",
        "# ----------------------------\n",
        "# 2️⃣ Katz Backoff (Quadrigram)\n",
        "# ----------------------------\n",
        "class KatzBackoff:\n",
        "    def __init__(self, counts, discount=0.5):\n",
        "        self.uni, self.bi, self.tri, self.quad = counts\n",
        "        self.d = discount\n",
        "        self.total = sum(self.uni.values())\n",
        "\n",
        "    def prob(self, ngram):\n",
        "        w1, w2, w3, w4 = ngram\n",
        "        q = (w1, w2, w3, w4)\n",
        "        t = (w1, w2, w3)\n",
        "        c4 = self.quad.get(q, 0)\n",
        "        c3 = self.tri.get(t, 0)\n",
        "        if c3 > 0:\n",
        "            return max(c4 - self.d, 0) / c3\n",
        "        return self._backoff_tri((w2, w3, w4))\n",
        "\n",
        "    def _backoff_tri(self, tri):\n",
        "        w2, w3, w4 = tri\n",
        "        t = (w2, w3, w4)\n",
        "        b = (w2, w3)\n",
        "        c3 = self.tri.get(t, 0)\n",
        "        c2 = self.bi.get(b, 0)\n",
        "        if c3 > 0:\n",
        "            return max(c3 - self.d, 0) / c2\n",
        "        return self._backoff_bi((w3, w4))\n",
        "\n",
        "    def _backoff_bi(self, bi):\n",
        "        w3, w4 = bi\n",
        "        c2 = self.bi.get((w3, w4), 0)\n",
        "        c1 = self.uni.get(w3, 0)\n",
        "        if c2 > 0:\n",
        "            return max(c2 - self.d, 0) / c1\n",
        "        return self.uni.get(w4, 0) / self.total\n",
        "\n",
        "# -----------------------------------\n",
        "# 3️⃣ Kneser–Ney Smoothing (Quadrigram)\n",
        "# -----------------------------------\n",
        "class KneserNey:\n",
        "    def __init__(self, counts, discount=0.75):\n",
        "        self.uni, self.bi, self.tri, self.quad = counts\n",
        "        self.D = discount\n",
        "\n",
        "    def continuation_prob(self, word):\n",
        "        return sum(1 for bg in self.bi if bg[1] == word) / len(self.bi)\n",
        "\n",
        "    def prob(self, ngram):\n",
        "        w1, w2, w3, w4 = ngram\n",
        "        quad = (w1, w2, w3, w4)\n",
        "        tri  = (w1, w2, w3)\n",
        "        c4 = self.quad.get(quad, 0)\n",
        "        c3 = self.tri.get(tri, 0)\n",
        "        if c3 > 0:\n",
        "            return max(c4 - self.D, 0)/c3 + (self.D/c3)*self._lower(tri[1:], w4)\n",
        "        return self._lower(tri[1:], w4)\n",
        "\n",
        "    def _lower(self, bi, w):\n",
        "        c3 = self.tri.get((bi[0], bi[1], w), 0)\n",
        "        c2 = self.bi.get(bi, 0)\n",
        "        if c2 > 0:\n",
        "            return max(c3 - self.D, 0)/c2 + (self.D/c2)*self.continuation_prob(w)\n",
        "        return self.continuation_prob(w)\n",
        "\n",
        "# ---------------------------\n",
        "# 4️⃣ Sentence Generation\n",
        "# ---------------------------\n",
        "class SentenceGenerator:\n",
        "    def __init__(self, model, vocab):\n",
        "        self.model = model\n",
        "        self.vocab = vocab\n",
        "\n",
        "    def greedy(self, max_len=30):\n",
        "        sent = [\"<s>\", \"<s>\", \"<s>\"]\n",
        "        while len(sent) < max_len:\n",
        "            # Prevent generating \"<s>\" if the previous token is also \"<s>\"\n",
        "            if sent[-1] == \"<s>\":\n",
        "                probs = {w: self.model.prob((sent[-3], sent[-2], sent[-1], w))\n",
        "                         for w in self.vocab if w != \"<s>\"}\n",
        "            else:\n",
        "                probs = {w: self.model.prob((sent[-3], sent[-2], sent[-1], w))\n",
        "                         for w in self.vocab}\n",
        "\n",
        "            # Handle the case where all remaining probabilities are zero\n",
        "            if not probs:\n",
        "                break\n",
        "\n",
        "            nxt = max(probs, key=probs.get)\n",
        "            sent.append(nxt)\n",
        "            if nxt == \"</s>\":\n",
        "                break\n",
        "        return sent\n",
        "\n",
        "    def beam_search(self, beam_size=20, max_len=30):\n",
        "        beams = [([\"<s>\", \"<s>\", \"<s>\"], 0.0)]\n",
        "        for _ in range(max_len):\n",
        "            new_beams = []\n",
        "            for seq, score in beams:\n",
        "                if seq[-1] == \"</s>\":\n",
        "                    new_beams.append((seq, score))\n",
        "                    continue\n",
        "                for w in self.vocab:\n",
        "                    p = self.model.prob((seq[-3], seq[-2], seq[-1], w))\n",
        "                    new_beams.append((seq + [w], score + math.log(p + 1e-12)))\n",
        "            beams = sorted(new_beams, key=lambda x: x[1], reverse=True)[:beam_size]\n",
        "        return beams[0][0]\n",
        "\n",
        "# --------------------------\n",
        "# 5️⃣ Run & save sentences\n",
        "# --------------------------\n",
        "import os\n",
        "os.makedirs(\"/content/generated_sentences\", exist_ok=True)\n",
        "\n",
        "def generate_and_save(generator, method, n=100, out_file=\"out.txt\"):\n",
        "    sentences = []\n",
        "    with tqdm(total=n, desc=f\"{method}\") as pbar:\n",
        "        for _ in range(n):\n",
        "            if method == \"Greedy\":\n",
        "                s = generator.greedy()\n",
        "            else:\n",
        "                s = generator.beam_search()\n",
        "            sentences.append(\" \".join(s))\n",
        "            pbar.update(1)\n",
        "    with open(out_file, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(\"\\n\".join(sentences))\n",
        "    print(f\"✅ Saved {n} sentences to {out_file}\")\n",
        "\n",
        "# Katz Backoff\n",
        "katz = KatzBackoff(counts_all)\n",
        "gen_katz = SentenceGenerator(katz, vocab)\n",
        "generate_and_save(gen_katz, \"Greedy\", 100,\n",
        "                  \"/content/generated_sentences/katz_greedy.txt\")\n",
        "generate_and_save(gen_katz, \"Beam\", 100,\n",
        "                  \"/content/generated_sentences/katz_beam.txt\")\n",
        "\n",
        "# Kneser–Ney\n",
        "kn = KneserNey(counts_all)\n",
        "gen_kn = SentenceGenerator(kn, vocab)\n",
        "generate_and_save(gen_kn, \"Greedy\", 100,\n",
        "                  \"/content/generated_sentences/kn_greedy.txt\")\n",
        "generate_and_save(gen_kn, \"Beam\", 100,\n",
        "                  \"/content/generated_sentences/kn_beam.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "117b2803",
        "outputId": "fb387e5e-38d1-44b3-f23d-1b7c18c0e533"
      },
      "source": [
        "# Inspect the structure of the loaded data\n",
        "print(type(data))\n",
        "if isinstance(data, list) and len(data) > 0:\n",
        "    print(type(data[0]))\n",
        "    if isinstance(data[0], dict):\n",
        "        print(data[0].keys())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "<class 'dict'>\n",
            "dict_keys(['document_id', 'original_text', 'sentences', 'document_stats'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Quadgram LM + Katz Backoff + Kneser–Ney + Sentence Generation\n",
        "# (Greedy + Beam search) with progress bar and file saving\n",
        "# ============================================================\n",
        "\n",
        "import pickle\n",
        "from collections import Counter\n",
        "import math\n",
        "from tqdm import tqdm   # <-- for progress bar\n",
        "\n",
        "# -------------------------------\n",
        "# 1️⃣ Load dataset & build counts\n",
        "# -------------------------------\n",
        "with open(\"/content/tokenized_data_complete.pkl\", \"rb\") as f:   # <-- change to your file\n",
        "    data = pickle.load(f)\n",
        "\n",
        "# Fix: Iterate directly through the list and access the 'tokens' key\n",
        "sentences = [s[\"sentences\"] for s in data]\n",
        "\n",
        "uni_counts  = Counter()\n",
        "bi_counts   = Counter()\n",
        "tri_counts  = Counter()\n",
        "quad_counts = Counter()\n",
        "\n",
        "for sentence_list in sentences:\n",
        "    for token_info in sentence_list:\n",
        "        seq = [\"<s>\", \"<s>\", \"<s>\"] + token_info[\"tokens\"] + [\"</s>\"]\n",
        "        for i in range(len(seq)):\n",
        "            uni_counts[seq[i]] += 1\n",
        "            if i >= 1:\n",
        "                bi_counts[(seq[i-1], seq[i])] += 1\n",
        "            if i >= 2:\n",
        "                tri_counts[(seq[i-2], seq[i-1], seq[i])] += 1\n",
        "            if i >= 3:\n",
        "                quad_counts[(seq[i-3], seq[i-2], seq[i-1], seq[i])] += 1\n",
        "\n",
        "counts_all = [uni_counts, bi_counts, tri_counts, quad_counts]\n",
        "vocab = list(uni_counts.keys())\n",
        "\n",
        "# ----------------------------\n",
        "# 2️⃣ Katz Backoff (Quadrigram)\n",
        "# ----------------------------\n",
        "class KatzBackoff:\n",
        "    def __init__(self, counts, discount=0.5):\n",
        "        self.uni, self.bi, self.tri, self.quad = counts\n",
        "        self.d = discount\n",
        "        self.total = sum(self.uni.values())\n",
        "\n",
        "    def prob(self, ngram):\n",
        "        w1, w2, w3, w4 = ngram\n",
        "        q = (w1, w2, w3, w4)\n",
        "        t = (w1, w2, w3)\n",
        "        c4 = self.quad.get(q, 0)\n",
        "        c3 = self.tri.get(t, 0)\n",
        "        if c3 > 0:\n",
        "            return max(c4 - self.d, 0) / c3\n",
        "        return self._backoff_tri((w2, w3, w4))\n",
        "\n",
        "    def _backoff_tri(self, tri):\n",
        "        w2, w3, w4 = tri\n",
        "        t = (w2, w3, w4)\n",
        "        b = (w2, w3)\n",
        "        c3 = self.tri.get(t, 0)\n",
        "        c2 = self.bi.get(b, 0)\n",
        "        if c3 > 0:\n",
        "            return max(c3 - self.d, 0) / c2\n",
        "        return self._backoff_bi((w3, w4))\n",
        "\n",
        "    def _backoff_bi(self, bi):\n",
        "        w3, w4 = bi\n",
        "        c2 = self.bi.get((w3, w4), 0)\n",
        "        c1 = self.uni.get(w3, 0)\n",
        "        if c2 > 0:\n",
        "            return max(c2 - self.d, 0) / c1\n",
        "        return self.uni.get(w4, 0) / self.total\n",
        "\n",
        "# -----------------------------------\n",
        "# 3️⃣ Kneser–Ney Smoothing (Quadrigram)\n",
        "# -----------------------------------\n",
        "class KneserNey:\n",
        "    def __init__(self, counts, discount=0.75):\n",
        "        self.uni, self.bi, self.tri, self.quad = counts\n",
        "        self.D = discount\n",
        "\n",
        "    def continuation_prob(self, word):\n",
        "        return sum(1 for bg in self.bi if bg[1] == word) / len(self.bi)\n",
        "\n",
        "    def prob(self, ngram):\n",
        "        w1, w2, w3, w4 = ngram\n",
        "        quad = (w1, w2, w3, w4)\n",
        "        tri  = (w1, w2, w3)\n",
        "        c4 = self.quad.get(quad, 0)\n",
        "        c3 = self.tri.get(tri, 0)\n",
        "        if c3 > 0:\n",
        "            return max(c4 - self.D, 0)/c3 + (self.D/c3)*self._lower(tri[1:], w4)\n",
        "        return self._lower(tri[1:], w4)\n",
        "\n",
        "    def _lower(self, bi, w):\n",
        "        c3 = self.tri.get((bi[0], bi[1], w), 0)\n",
        "        c2 = self.bi.get(bi, 0)\n",
        "        if c2 > 0:\n",
        "            return max(c3 - self.D, 0)/c2 + (self.D/c2)*self.continuation_prob(w)\n",
        "        return self.continuation_prob(w)\n",
        "\n",
        "# ---------------------------\n",
        "# 4️⃣ Sentence Generation\n",
        "# ---------------------------\n",
        "class SentenceGenerator:\n",
        "    def __init__(self, model, vocab):\n",
        "        self.model = model\n",
        "        self.vocab = vocab\n",
        "\n",
        "    def greedy(self, max_len=30):\n",
        "        sent = [\"<s>\", \"<s>\", \"<s>\"]\n",
        "        while len(sent) < max_len:\n",
        "            # Prevent generating \"<s>\" if the previous token is also \"<s>\"\n",
        "            if sent[-1] == \"<s>\":\n",
        "                probs = {w: self.model.prob((sent[-3], sent[-2], sent[-1], w))\n",
        "                         for w in self.vocab if w != \"<s>\"}\n",
        "            else:\n",
        "                probs = {w: self.model.prob((sent[-3], sent[-2], sent[-1], w))\n",
        "                         for w in self.vocab}\n",
        "\n",
        "            # Handle the case where all remaining probabilities are zero\n",
        "            if not probs:\n",
        "                break\n",
        "\n",
        "            nxt = max(probs, key=probs.get)\n",
        "            sent.append(nxt)\n",
        "            if nxt == \"</s>\":\n",
        "                break\n",
        "        return sent\n",
        "\n",
        "    def beam_search(self, beam_size=20, max_len=30):\n",
        "        beams = [([\"<s>\", \"<s>\", \"<s>\"], 0.0)]\n",
        "        for _ in range(max_len):\n",
        "            new_beams = []\n",
        "            for seq, score in beams:\n",
        "                if seq[-1] == \"</s>\":\n",
        "                    new_beams.append((seq, score))\n",
        "                    continue\n",
        "                for w in self.vocab:\n",
        "                    p = self.model.prob((seq[-3], seq[-2], seq[-1], w))\n",
        "                    new_beams.append((seq + [w], score + math.log(p + 1e-12)))\n",
        "            beams = sorted(new_beams, key=lambda x: x[1], reverse=True)[:beam_size]\n",
        "        return beams[0][0]\n",
        "\n",
        "# --------------------------\n",
        "# 5️⃣ Run & save sentences\n",
        "# --------------------------\n",
        "import os\n",
        "os.makedirs(\"/content/generated_sentences\", exist_ok=True)\n",
        "\n",
        "def generate_and_save(generator, method, n=100, out_file=\"out.txt\"):\n",
        "    sentences = []\n",
        "    with tqdm(total=n, desc=f\"{method}\") as pbar:\n",
        "        for _ in range(n):\n",
        "            if method == \"Greedy\":\n",
        "                s = generator.greedy()\n",
        "            else:\n",
        "                s = generator.beam_search()\n",
        "            sentences.append(\" \".join(s))\n",
        "            pbar.update(1)\n",
        "    with open(out_file, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(\"\\n\".join(sentences))\n",
        "    print(f\"✅ Saved {n} sentences to {out_file}\")\n",
        "\n",
        "# Katz Backoff\n",
        "katz = KatzBackoff(counts_all)\n",
        "gen_katz = SentenceGenerator(katz, vocab)\n",
        "generate_and_save(gen_katz, \"Greedy\", 100,\n",
        "                  \"/content/generated_sentences/katz_greedy.txt\")\n",
        "generate_and_save(gen_katz, \"Beam\", 100,\n",
        "                  \"/content/generated_sentences/katz_beam.txt\")\n",
        "\n",
        "# Kneser–Ney\n",
        "kn = KneserNey(counts_all)\n",
        "gen_kn = SentenceGenerator(kn, vocab)\n",
        "generate_and_save(gen_kn, \"Greedy\", 100,\n",
        "                  \"/content/generated_sentences/kn_greedy.txt\")\n",
        "generate_and_save(gen_kn, \"Beam\", 100,\n",
        "                  \"/content/generated_sentences/kn_beam.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ML4TT_7c1HQC",
        "outputId": "5afcc8d2-8159-488f-81b9-37f354695923"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Greedy: 100%|██████████| 100/100 [04:55<00:00,  2.95s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved 100 sentences to /content/generated_sentences/katz_greedy.txt\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Beam: 100%|██████████| 100/100 [5:28:02<00:00, 196.82s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved 100 sentences to /content/generated_sentences/katz_beam.txt\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rGreedy:   0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YMQ6WC6WZCw9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}